# FURI Soil Hyperspectral Reconstruction  
### Variational Autoencoders (Conv-VAE & Spatial ViT-VAE) for VNIR Soil Spectral Data  
**Researcher:** Prajakta Kadukar  
**Mentor:** Prof. Nakul Gopalan and Prof. Saurav Kumar 
**Program:** FURI â€” Fulton Undergraduate Research Initiative (Fall 2025)  
**Cluster:** ASU Sol HPC  

---

## Project Overview  
Hyperspectral soil imagery contains ~200 spectral bands per pixel and encodes rich information about mineralogy, soil composition, carbon content, and surface properties.  
However, these cubes are **high-dimensional**, expensive to store, and computationally heavy.

This project explores **Variational Autoencoders (VAEs)** â€” particularly a **Spatial Vision Transformer VAE** â€” to compress and reconstruct hyperspectral soil VNIR tiles:

- Input shape: **145 Ã— 145 Ã— 200**  
- VNIR2 dataset from `/scratch/mkhorram/Soil/VNIR2/`  
- Compression target:  
  - Conv-VAE â†’ latent dim 1024  
  - Spatial ViT-VAE â†’ latent map **16 Ã— 16 Ã— C**

The ViT-VAE significantly outperforms the baseline Conv-VAE.

---

## ğŸ“ Repository Structure

furi-soil-hyperspectral-vae/
â”‚
â”œâ”€â”€ code/ # All training, evaluation, and model scripts
â”‚ â”œâ”€â”€ hsi_dataset.py # Rasterio-based loader for .bip hyperspectral cubes
â”‚ â”œâ”€â”€ train_vnir_vae.py # Main training script (Conv/VIT/Spatial-VIT)
â”‚ â”œâ”€â”€ eval_vnir_vae.py # Evaluation: PSNR + SAM
â”‚ â”œâ”€â”€ extract_latents.py # Extract latent vectors/maps
â”‚ â”œâ”€â”€ visualize_latent_pca.py # PCA visualization of latents
â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ vae_conv.py # Baseline convolutional VAE
â”‚ â”‚ â”œâ”€â”€ vit_vae.py # Spatial transformer VAE
â”‚ â””â”€â”€ utils/metrics.py
â”‚
â”œâ”€â”€ jobs/ # SLURM job scripts for Sol HPC
â”‚ â”œâ”€â”€ run_train.sbatch
â”‚ â”œâ”€â”€ vnir2_conv_main.sbatch
â”‚ â”œâ”€â”€ vnir2_vit_spatial_main.sbatch
â”‚ â””â”€â”€ vnir2_latents_main.sbatch
â”‚
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ conv/ # Conv-VAE results
â”‚ â”‚ â”œâ”€â”€ eval_ep015.txt
â”‚ â”‚ â”œâ”€â”€ preview_ep015.png
â”‚ â”‚ â””â”€â”€ latent_pca_ep025.png
â”‚ â””â”€â”€ vit_spatial/ # Spatial ViT-VAE results
â”‚ â”œâ”€â”€ eval_ep025.txt
â”‚ â”œâ”€â”€ preview_ep025.png
â”‚ â””â”€â”€ latent_pca_ep025.png
â”‚
â””â”€â”€ .gitignore

---

## Quantitative Results

### **Final Evaluation (on full VNIR2 dataset)**  
| Model | Latent Dim | PSNR â†‘ | SAM â†“ |
|-------|------------|-------|--------|
| **Spatial ViT-VAE (ep025)** | 16Ã—16Ã—C (2048) | **24.68 dB** | **0.0628 rad** |
| **Conv-VAE (ep015)** | 1024 | 16.61 dB | 0.1713 rad |

**Result:** The Spatial ViT-VAE strongly outperforms the Conv-VAE in spectral/angular fidelity.

---

## Reconstruction Samples

### **Spatial ViT-VAE Reconstruction (ep025)**
![ViT-VAE Reconstruction](results/vit_spatial/preview_ep025.png)

### **Conv-VAE Reconstruction (ep015)**
![Conv-VAE Reconstruction](results/conv/preview_ep015.png)

---

## Latent Space PCA

### Spatial ViT-VAE Latents  
![ViT Latent PCA](results/vit_spatial/latent_pca_ep025.png)

### Conv-VAE Latents  
![Conv Latent PCA](results/conv/latent_pca_ep025.png)

---

## Training Instructions

### On ASU Sol HPC:
Activate environment:

```bash
source ~/venvs/furi310/bin/activate
cd /scratch/pkadukar/soil_proj

Train Spatial ViT-VAE

python -u code/train_vnir_vae.py \
  --model vit_spatial \
  --pattern "/scratch/mkhorram/Soil/VNIR2/*.bip" \
  --epochs 25 \
  --batch 8 \
  --lr 3e-4 \
  --beta 1e-3 \
  --amp \
  --latent 8 \
  --outdir "runs/vnir2_vit_spatial_main_metrics"

Evaluate

python -u code/eval_vnir_vae.py \
  --model vit_spatial \
  --ckpt runs/vnir2_vit_spatial_main_metrics/ep025.pt \
  --pattern "/scratch/mkhorram/Soil/VNIR2/*.bip" \
  --batch 16 \
  --latent 8 \
  --outdir runs/vnir2_vit_spatial_main_metrics/eval_ep025


